{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Needs the package Pandas to be installed. Check Anaconda Environments and Packages.\n",
    "from sklearn.decomposition import PCA # Needs SciKit Learn package to be installed. Check Anaconda Environments and Packages.4\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces94_male = readFaces94MaleFaces(gray=True)\n",
    "faces94_female = readFaces94FemaleFaces(gray=True)\n",
    "faces94_malestaff = readFaces94MaleStaffFaces(gray=True)\n",
    "\n",
    "dataset = np.vstack((faces94_male, faces94_female, faces94_malestaff))\n",
    "\n",
    "dataset_N, height, width = dataset.shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data centralization and calculate of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=dataset.reshape(dataset_N, height*width)/255 # normalizaciÃ³n para reducir complejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_1=[]\n",
    "start_time = time.time()\n",
    "for i in range(A.shape[0]):\n",
    "    d = np.linalg.norm(np.subtract(A[i], A), ord=2, axis=1)\n",
    "    s=np.sum(np.sum(d,axis=0)) # suma de las difenrecias\n",
    "    dist_1.append(s) # Guardando la suma de las diferencias de la imagen i a las demas\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"Time elapsed for operation: {}\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min_1=np.argmin(np.array(dist_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[Min_1],plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min_1 #Median image index: 394 (including male, female, malestaff and landscapes)\n",
    "      #Median image index: 393 (including only male, female and malestaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[393],plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Median_all = dataset[393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset.reshape(dataset_N, height*width) - Median_all.reshape(height*width)\n",
    "datasetmedian=(1/(dataset_N-1))*(np.dot(data,data.T)) # Covariance matrix\n",
    "print(datasetmedian.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(datasetmedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face space: selection of subspace componets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: investigator's criteria of varibility captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_percentage = 0.85 # Selected variability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_eig = np.sum(s)\n",
    "percentage_variance = np.divide(s, sum_eig)\n",
    "sum_var = 0\n",
    "num_var = 0\n",
    "for i in np.arange(percentage_variance.shape[0]):\n",
    "    if sum_var >= representation_percentage:\n",
    "        num_var = i\n",
    "        break;\n",
    "    \n",
    "    sum_var += percentage_variance[i]\n",
    "    \n",
    "num_var_select=num_var    \n",
    "print(\"Principal components number: \",num_var_select)\n",
    "print(\"Percent of variability captured: \",sum_var*100)\n",
    "print(\"Images in datasets\",dataset_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: investigator's criteria of threshold contribution value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_per=np.cumsum(percentage_variance)\n",
    "for i in range(1,len(s)):\n",
    "    change=(cum_per[i]-cum_per[i-1])/cum_per[i-1]*100\n",
    "    if(change<.01):\n",
    "        num_var=i-1\n",
    "        print(\"First\",num_var, \"components with \",cum_per[num_var]*100,\"percent of variability captured and from which the contribution is less than 0.01%\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cum_per*100)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Cumulative Summation of the Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EigenvectorsA=np.dot(data.T,u[:,0:num_var_select])\n",
    "NormEigenvectorsA = preprocessing.normalize(EigenvectorsA,axis=0, norm='l2')\n",
    "print(np.linalg.norm(NormEigenvectorsA[:,5],ord=None))#check normalizacion vectores propios de XT.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 4\n",
    "plt.figure(figsize=(30,20))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(NormEigenvectorsA[:,i].reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection of an image on face space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0.8\n",
    "step=0.06\n",
    "stop=1\n",
    "\n",
    "facespace(percentage_variance,dataset,data,Median_all,u,dataset_N,height,width,start,step,stop,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Principal components number: \",num_var_select)\n",
    "print(\"Percent of variability captured: \",sum_var*100)\n",
    "print(\"Images in datasets\",dataset_N)\n",
    "print(\"Omega matrix facespace\",np.dot(data,NormEigenvectorsA).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "n=widgets.BoundedFloatText(value=2690,min=0,max=dataset_N,description='image:')\n",
    "display(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_image=int(n.value)\n",
    "specificimage(data,dataset,NormEigenvectorsA,Median_all,N_image,dataset_N,height,width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomimage(data,dataset,NormEigenvectorsA,Median_all,dataset_N,height,width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReconstructed=np.dot(np.dot(data,NormEigenvectorsA),NormEigenvectorsA.T)+Median_all.reshape(height*width)\n",
    "print(dataReconstructed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm=widgets.Dropdown(options=['1', '2', 'inf'],value='2',description='Norm:',disabled=False)\n",
    "display(Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(Norm.value)=='inf':\n",
    "    ordn=np.inf\n",
    "else:\n",
    "    ordn=int(Norm.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edistance = np.linalg.norm(np.subtract(dataReconstructed, dataset.reshape(dataset_N, height*width)), ord=ordn, axis=1)\n",
    "print(edistance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histbox(edistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold, outliers, zsort, indexsort, z=outlierseigenfaces(edistance,3)\n",
    "\n",
    "print('Outliers threshold method=',np.size(outliers))\n",
    "print('threshold=',threshold)\n",
    "CVresult={'outliers distance':outliers,'z':zsort}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.sort_values('z', axis = 0, ascending = False, inplace = True, na_position ='first') \n",
    "df.head(np.size(outliers)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low and high distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Similar Image\")\n",
    "ax1.imshow(dataset[indexsort[0]], plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"Dissimilar Image\")\n",
    "ax2.imshow(dataset[indexsort[-1]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 2\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"z \"+str(z[indexsort[-(i+1)]]),fontsize=20)\n",
    "    plt.imshow(dataset[indexsort[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscapes = np.array(readLandsCapeImage(gray=True))\n",
    "\n",
    "landimages(landscapes,height,width,Median_all,NormEigenvectorsA,ordn,outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landimage=landscapes.reshape(landscapes.shape[0],height*width)-Median_all.reshape(height*width)\n",
    "dataReconstructedland=np.dot(np.dot(landimage,NormEigenvectorsA),NormEigenvectorsA.T)+Median_all.reshape(height*width)\n",
    "print(dataReconstructedland.shape)\n",
    "\n",
    "edistanceland = np.linalg.norm(np.subtract(dataReconstructedland, landscapes.reshape(landscapes.shape[0], height*width)), ord=ordn, axis=1)\n",
    "totaldistance=np.append(edistance,edistanceland)\n",
    "histbox(totaldistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.ones(dataset_N)\n",
    "y_true=np.append(y_true,np.zeros(landscapes.shape[0]))\n",
    "y_pred=(totaldistance<=outliers[0])*1\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print('TP=', tp,'TN=',tn,'FP=',fp,'FN=', fn)\n",
    "print('accuracy= ', (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Heatmap\")\n",
    "prediction_data = {'y_Actual': y_true,'y_Predicted': y_pred}\n",
    "df = pd.DataFrame(prediction_data, columns=['y_Actual','y_Predicted'])\n",
    "confusionmatrix1 = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "ax=sns.heatmap(confusionmatrix1, annot=True,cmap='Blues', fmt='.0f');\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outlier in outliers:\n",
    "    print(np.where(outlier > edistanceland))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_land= int(np.where(edistanceland < outliers[6])[0][3])\n",
    "landimage=landscapes[N_land].reshape(height*width)-Median_all.reshape(height*width)#seleccionar imagen individual\n",
    "wland=np.dot(landimage,NormEigenvectorsA)#pesos w de cada Eigenface en subespacio generado\n",
    "Reconstland=np.dot(wland,NormEigenvectorsA.T)+Median_all.reshape(height*width)#es mas claro w*vectores propios transpuestos\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Land image\")\n",
    "ax1.imshow(landscapes[N_land], plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"Reconstructed land Image\")\n",
    "ax2.imshow(Reconstland.reshape(height, width), plt.cm.gray)\n",
    "print('distancia',edistanceland[N_land])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, tncv, fpcv, fncv, tpcv=kfold(y_true,landscapes,dataset,height,width,ordn)\n",
    "CVresult={'accuracy':accuracy,'tn':tncv,'fp':fpcv,'fn':fncv,'tp':tpcv}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
