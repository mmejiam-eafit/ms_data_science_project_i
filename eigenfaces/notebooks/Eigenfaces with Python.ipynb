{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Needs the package Pandas to be installed. Check Anaconda Environments and Packages.\n",
    "from sklearn.decomposition import PCA # Needs SciKit Learn package to be installed. Check Anaconda Environments and Packages.4\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET FACES 94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "In order to prepare the image dataset to proceed with the final stages of modeling and valuation processes. It is unavoidable to standardize the images features on the initial dataset (codename - faces94) and the external images use it on the future testing activities under the following conditions:\n",
    "\n",
    "**General Images Characteristics**:\n",
    "\n",
    "* File Format *.jpg\n",
    "* Images on Gray Scale.\n",
    "* Size 180x200 for the images on the dataset (codename- faces94)\n",
    "\n",
    "**Activities**:\n",
    "\n",
    "* Organize the images on a short-listed to prepare a new dataset.\n",
    "* Exclude from the dataset all the images without the *.jpg format.\n",
    "* On the OpenCV library of Python, upload the images and storage the matrix in arrays for numeric treatment.\n",
    "* On the OpenCV library of Python, change the images to gray-scale and resize the photos to 180x200.\n",
    "* Finally, the outcome is a new dataset with the proper images for testing and modeling face recognition. With the Eigenfaces model to apply the Principal Component Analysis (PCA) so represent the face images in a low dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face94_male = readFaces94MaleFaces(gray=True)\n",
    "plt.imshow(face94_male[0], plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, height, width = face94_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_faces = np.ones(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_face = np.mean(face94_male.reshape(N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_face, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_face = np.median(face94_male.reshape(N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(median_face, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images of natual landscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The landscape images were obtain of **ImageNet** database [ImageNet database](http://image-net.org/) , \n",
    "each one of the directions is [online](http://image-net.org/api/text/imagenet.synset.geturls?wnid=n13104059). We use cv2 package by read and resize images, then we create an Numpy array with a gray scale of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscapes = np.array(readLandsCapeImage(gray=True)) # Read dataset\n",
    "plt.imshow(landscapes[45], plt.cm.gray); # show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_landscapes = np.zeros(landscapes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.vstack((face94_male, landscapes))\n",
    "plt.imshow(dataset[-1], plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((labels_faces, labels_landscapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_N, height, width = dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_with_noise = np.mean(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_with_noise, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"mean with noise\")\n",
    "ax1.imshow(mean_with_noise, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"mean\")\n",
    "ax2.imshow(mean_face, plt.cm.gray)\n",
    "Dis=np.linalg.norm(mean_with_noise - mean_face, ord=2, keepdims=False)\n",
    "print(\"Distance \"+ str(Dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_with_noise = np.median(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(median_with_noise, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"median with noise\")\n",
    "ax1.imshow(median_with_noise, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"median\")\n",
    "ax2.imshow(median_face, plt.cm.gray)\n",
    "Dis=np.linalg.norm(median_with_noise - median_face, ord=2, keepdims=False)\n",
    "print(\"Distance \"+ str(Dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median face as a real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=dataset.reshape(dataset_N, height*width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_1=[]\n",
    "for i in range(A.shape[0]):\n",
    "    D=abs(np.subtract(A[i], A))  \n",
    "    s=sum(np.sum(D,axis=0)) \n",
    "    dist_1.append(s) \n",
    "    \n",
    "Min_1=np.argmin(np.array(dist_1))\n",
    "\n",
    "plt.imshow(dataset[Min_1],plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show atypical data distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_info = getNormsAndDistanceInfoFromBaseImage(base_image=mean_with_noise, array_images=dataset, labels=labels)\n",
    "visualizeOutlierInfo(distance_info,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_info['falsitude_metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show atypical data distances (outliers interquartile range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeOutlierInfo2(distance_info,dataset,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_info['falsitude_metrics_iqr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normas: Norm1.0  Norm2.0  Norm3.0  Norminf  Norm2.5  Norm0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_norm = \"Norminf\"\n",
    "cols = 6\n",
    "rows = int(np.ceil(distance_info[\"outliers\"][selected_norm][\"indices\"].shape[0]/cols))\n",
    "plt.figure(figsize=(180,200))\n",
    "for i in np.arange(distance_info[\"outliers\"][selected_norm][\"indices\"].shape[0]):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(dataset[distance_info[\"outliers\"][selected_norm][\"indices\"][i]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_norm = \"Norm1.0\"\n",
    "selected_outliers = \"outliersiqr\"\n",
    "Distance=distance_info[\"norms\"][selected_norm][distance_info[selected_outliers][selected_norm]['indices']]\n",
    "Ind=distance_info[selected_outliers][selected_norm]['indices']\n",
    "Distance, Ind =zip(*sorted(zip(Distance, Ind)))\n",
    "cols = 6\n",
    "rows = int(np.ceil(len(Ind)/cols))\n",
    "plt.figure(figsize=(180,200))\n",
    "for i in np.arange(len(Ind)):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(dataset[Ind[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces94_male = readFaces94MaleFaces(gray=True)\n",
    "faces94_female = readFaces94FemaleFaces(gray=True)\n",
    "faces94_malestaff = readFaces94MaleStaffFaces(gray=True)\n",
    "landscapes = np.array(readLandsCapeImage(gray=True))\n",
    "\n",
    "dataset = np.vstack((faces94_male, faces94_female, faces94_malestaff, landscapes))\n",
    "\n",
    "labels = np.concatenate((\n",
    "    np.ones(faces94_male.shape[0]),\n",
    "    np.full(faces94_female.shape[0], 2),\n",
    "    np.full(faces94_malestaff.shape[0], 3),\n",
    "    np.zeros(landscapes.shape[0])\n",
    "))\n",
    "\n",
    "dataset_N, height, width = dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all = np.mean(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_all, plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_norm = dataset/255\n",
    "dataset_norm_cov = np.cov(dataset_norm.reshape(dataset_N, height*width))\n",
    "\n",
    "np.linalg.det(dataset_norm_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(dataset_norm_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_norm = np.mean(dataset_norm.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "\n",
    "#lw = LedoitWolf(store_precision=True, assume_centered=True)\n",
    "#cov_all = lw.fit(\n",
    "#    np.subtract(dataset_norm, mean_norm).reshape(dataset_N, height*width)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_percentage = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_eig = np.sum(s)\n",
    "percentage_variance = np.divide(s, sum_eig)\n",
    "sum_var = 0\n",
    "num_var = 0\n",
    "for i in np.arange(percentage_variance.shape[0]):\n",
    "    if sum_var >= representation_percentage:\n",
    "        num_var = i\n",
    "        break;\n",
    "    \n",
    "    sum_var += percentage_variance[i]\n",
    "    \n",
    "num_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=num_var, whiten=True).fit(dataset.reshape(dataset_N, height*width))\n",
    "pca.components_.shape;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 6\n",
    "rows = int(np.floor(num_var/cols))\n",
    "plt.figure(figsize=(180,200))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(pca.components_[i].reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_face = pca.mean_.reshape(height, width)\n",
    "mean_face2 = np.mean(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"PCA mean\")\n",
    "ax1.imshow(mean_face, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"np mean\")\n",
    "ax2.imshow(mean_face2, plt.cm.gray)\n",
    "Dis=np.linalg.norm(mean_face - mean_face2, ord=2, keepdims=False)\n",
    "print(\"Distance \"+ str(Dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_projected = pca.transform(dataset.reshape(dataset_N, height*width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = np.matmul(dataset_projected[1235], pca.components_)\n",
    "plt.imshow(example_image.reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_projected, labels, test_size=0.3, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_true=y_test, y_pred=y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check parametric distribution of distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is evaluated if the metrics can be adjusted with a parametric distribution, for this purpose the chi-squared statistic is calculated (small p values indicates a better fit) and the Kolmogorov-Smirnov test (values greater than .05 indicate good fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=distance_info['norms']['Norm1.0']\n",
    "check_parametricDistribu_distances(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
