{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Needs the package Pandas to be installed. Check Anaconda Environments and Packages.\n",
    "from sklearn.decomposition import PCA # Needs SciKit Learn package to be installed. Check Anaconda Environments and Packages.4\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import time\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET FACES 94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "In order to prepare the image dataset to proceed with the final stages of modeling and valuation processes. It is unavoidable to standardize the images features on the initial dataset (codename - faces94) and the external images use it on the future testing activities under the following conditions:\n",
    "\n",
    "**General Images Characteristics**:\n",
    "\n",
    "* File Format *.jpg\n",
    "* Images on Gray Scale.\n",
    "* Size 180x200 for the images on the dataset (codename- faces94)\n",
    "\n",
    "**Activities**:\n",
    "\n",
    "* Organize the images on a short-listed to prepare a new dataset.\n",
    "* Exclude from the dataset all the images without the *.jpg format.\n",
    "* On the OpenCV library of Python, upload the images and storage the matrix in arrays for numeric treatment.\n",
    "* On the OpenCV library of Python, change the images to gray-scale and resize the photos to 180x200.\n",
    "* Finally, the outcome is a new dataset with the proper images for testing and modeling face recognition. With the Eigenfaces model to apply the Principal Component Analysis (PCA) so represent the face images in a low dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face94_male = readFaces94MaleFaces(gray=True)\n",
    "plt.imshow(face94_male[0], plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, height, width = face94_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_faces = np.ones(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_face = np.mean(face94_male.reshape(N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_face, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_face = np.median(face94_male.reshape(N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(median_face, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images of natural landscapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The landscape images were obtain of **ImageNet** database [ImageNet database](http://image-net.org/) , \n",
    "each one of the directions is [online](http://image-net.org/api/text/imagenet.synset.geturls?wnid=n13104059). We use cv2 package by read and resize images, then we create an Numpy array with a gray scale of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscapes = np.array(readLandsCapeImage(gray=True)) # Read dataset\n",
    "plt.imshow(landscapes[45], plt.cm.gray); # show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_landscapes = np.zeros(landscapes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.vstack((face94_male, landscapes))\n",
    "plt.imshow(dataset[-1], plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((labels_faces, labels_landscapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_N, height, width = dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_with_noise = np.mean(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_with_noise, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"mean with noise\")\n",
    "ax1.imshow(mean_with_noise, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"mean\")\n",
    "ax2.imshow(mean_face, plt.cm.gray)\n",
    "Dis=np.linalg.norm(mean_with_noise - mean_face, ord=2, keepdims=False)\n",
    "print(\"Distance \"+ str(Dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_with_noise = np.median(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(median_with_noise, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"median with noise\")\n",
    "ax1.imshow(median_with_noise, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"median\")\n",
    "ax2.imshow(median_face, plt.cm.gray)\n",
    "Dis=np.linalg.norm(median_with_noise - median_face, ord=2, keepdims=False)\n",
    "print(\"Distance \"+ str(Dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median face as a real image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=dataset.reshape(dataset_N, height*width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_1=[]\n",
    "start_time = time.time()\n",
    "for i in range(A.shape[0]):\n",
    "    d = np.linalg.norm(np.subtract(A[i], A), ord=2, axis=1)\n",
    "    s=np.sum(np.sum(d,axis=0)) # suma de las difenrecias\n",
    "    dist_1.append(s) # Guardando la suma de las diferencias de la imagen i a las demas\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"Time elapsed for operation: {}\".format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min_1=np.argmin(np.array(dist_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[Min_1],plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show atypical data distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_info = getNormsAndDistanceInfoFromBaseImage(base_image=mean_with_noise, array_images=dataset, labels=labels)\n",
    "visualizeOutlierInfo(distance_info,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_info['falsitude_metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show atypical data distances (outliers interquartile range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeOutlierInfo2(distance_info,dataset,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_info['falsitude_metrics_iqr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normas: Norm1.0  Norm2.0  Norm3.0  Norminf  Norm2.5  Norm0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_norm = \"Norminf\"\n",
    "cols = 6\n",
    "rows = int(np.ceil(distance_info[\"outliers\"][selected_norm][\"indices\"].shape[0]/cols))\n",
    "plt.figure(figsize=(180,200))\n",
    "for i in np.arange(distance_info[\"outliers\"][selected_norm][\"indices\"].shape[0]):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(dataset[distance_info[\"outliers\"][selected_norm][\"indices\"][i]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_norm = \"Norm1.0\"\n",
    "selected_outliers = \"outliersiqr\"\n",
    "Distance=distance_info[\"norms\"][selected_norm][distance_info[selected_outliers][selected_norm]['indices']]\n",
    "Ind=distance_info[selected_outliers][selected_norm]['indices']\n",
    "Distance, Ind =zip(*sorted(zip(Distance, Ind)))\n",
    "cols = 6\n",
    "rows = int(np.ceil(len(Ind)/cols))\n",
    "plt.figure(figsize=(180,200))\n",
    "for i in np.arange(len(Ind)):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(dataset[Ind[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces94_male = readFaces94MaleFaces(gray=True)\n",
    "faces94_female = readFaces94FemaleFaces(gray=True)\n",
    "faces94_malestaff = readFaces94MaleStaffFaces(gray=True)\n",
    "landscapes = np.array(readLandsCapeImage(gray=True))\n",
    "\n",
    "dataset = np.vstack((faces94_male, faces94_female, faces94_malestaff, landscapes))\n",
    "\n",
    "labels = np.concatenate((\n",
    "    np.ones(faces94_male.shape[0]),\n",
    "    np.full(faces94_female.shape[0], 2),\n",
    "    np.full(faces94_malestaff.shape[0], 3),\n",
    "    np.zeros(landscapes.shape[0])\n",
    "))\n",
    "\n",
    "dataset_N, height, width = dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all = np.mean(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_all, plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_norm = dataset/255\n",
    "dataset_norm_cov = np.cov(dataset_norm.reshape(dataset_N, height*width))\n",
    "\n",
    "np.linalg.det(dataset_norm_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(dataset_norm_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_percentage = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_eig = np.sum(s)\n",
    "percentage_variance = np.divide(s, sum_eig)\n",
    "sum_var = 0\n",
    "num_var = 0\n",
    "for i in np.arange(percentage_variance.shape[0]):\n",
    "    if sum_var >= representation_percentage:\n",
    "        num_var = i\n",
    "        break;\n",
    "    \n",
    "    sum_var += percentage_variance[i]\n",
    "    \n",
    "num_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=num_var, svd_solver='full').fit(dataset.reshape(dataset_N, height*width))\n",
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 6\n",
    "rows = int(np.floor(num_var/cols))\n",
    "plt.figure(figsize=(180,200))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(pca.components_[i].reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_face = pca.mean_.reshape(height, width)\n",
    "mean_face2 = np.mean(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"PCA mean\")\n",
    "ax1.imshow(mean_face, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"np mean\")\n",
    "ax2.imshow(mean_face2, plt.cm.gray)\n",
    "Dis=np.linalg.norm(mean_face - mean_face2, ord=2, keepdims=False)\n",
    "print(\"Distance \"+ str(Dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_projected = pca.transform(dataset.reshape(dataset_N, height*width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = np.random.randint(0, high=dataset_N, size=1)[0]\n",
    "example_image = np.matmul(dataset_projected[image_index], pca.components_)\n",
    "original_image = dataset[image_index]\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Original Image\")\n",
    "ax1.imshow(original_image, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"Reconstructed Image\")\n",
    "ax2.imshow(example_image.reshape(height,width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_projected, labels, test_size=0.3, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_true=y_test, y_pred=y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_test_pred, target_names=[\"landscape\", \"man\", \"woman\", \"man_staff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Heatmap\")\n",
    "classes_dict = {'Actual': y_test.tolist(), 'Predicted': y_test_pred.tolist()}\n",
    "classes_df = pd.DataFrame(classes_dict, columns=[\"Actual\", \"Predicted\"])\n",
    "conf_matrix = pd.crosstab(classes_df['Actual'], classes_df['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "ax=sns.heatmap(conf_matrix, annot=True,cmap='Blues', fmt='.0f');\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarize(labels, classes=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix = linkage(dataset_projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    linkage_matrix,\n",
    "    p=120,\n",
    "    truncate_mode='level'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check parametric distribution of distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is evaluated if the metrics can be adjusted with a parametric distribution, for this purpose the chi-squared statistic is calculated (small chi_square values indicates a better fit) and the Kolmogorov-Smirnov test (values greater than .05 indicate good fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=distance_info['norms']['Norm1.0']\n",
    "check_parametricDistribu_distances(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mahalanobis distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mahalanobis distance has the form $d_{i,j}=[(x_i-x_j)'M^{-1}(x_i-x_j)]^{\\frac{1}{2}}$ where $M^{-1}$ is the inverse of covariance matrix. To obtain $M^{-1}$, The LedoitWolf estimate is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.reshape(dataset_N, height*width)\n",
    "X_norm = np.divide(np.subtract(X, X.mean(axis=0)),  X.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = LedoitWolf(store_precision=True, assume_centered=True)\n",
    "cov_all = lw.fit(X_norm)\n",
    "inv_cov_all = lw.precision_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
